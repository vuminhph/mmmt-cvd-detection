{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, scipy as sp, scipy.io, scipy.io.wavfile\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.nn import ZeroPad2d\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from Const import *\n",
    "from helper_code import *\n",
    "from audio_util import AudioUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 25, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvggish import vggish, vggish_input\n",
    "\n",
    "# Initialise model and download weights\n",
    "embedding_model = vggish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4789f96b16fd46a1865ac9089ca305c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder = \"C:/Users/lumin/Desktop/Work/20212/Data/circor-heart-sound/final/test\"\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "patient_files = find_patient_files(data_folder)\n",
    "\n",
    "recording_cycles_embeddings = None\n",
    "\n",
    "for patient in tqdm(patient_files):\n",
    "    current_patient_data = load_patient_data(patient)\n",
    "    current_recordings_paths, current_recordings = load_recordings(data_folder, current_patient_data, get_paths=True, preprocess=False)\n",
    "\n",
    "    cur_recording_cycles_embeddings = torch.zeros((len(recording_locations), 128 * EMBEDDING_ROWS))\n",
    "\n",
    "    for i in range(len(current_recordings_paths)):\n",
    "        segmentation_file_path = AudioUtil.get_segmentation_file(current_recordings_paths[i])\n",
    "        cardiac_states = AudioUtil.get_cardiac_states(segmentation_file_path)\n",
    "\n",
    "        if cardiac_states is None:\n",
    "            continue\n",
    "\n",
    "        cardiac_cycles = AudioUtil.split_cardiac_cycles(current_recordings[i], cardiac_states)\n",
    "        \n",
    "        loc_embeddings = None\n",
    "\n",
    "        for cycle in cardiac_cycles:\n",
    "            cur_cycle = AudioUtil.audio_norm(cycle)\n",
    "            cur_cycle = AudioUtil.pad_signal(cur_cycle, MAX_DURATION)\n",
    "\n",
    "            example = vggish_input.waveform_to_examples(data=cur_cycle, sample_rate=NEW_SAMPLING_RATE)\n",
    "            embeddings = embedding_model.forward(example)\n",
    "            \n",
    "            loc_embeddings = loc_embeddings = embeddings if loc_embeddings is None else torch.vstack((loc_embeddings, embeddings))\n",
    "\n",
    "        # Pad embeddings to reach size of (EMBEDDING_ROWS, 128)\n",
    "        cur_no_rows = loc_embeddings.size()[0]\n",
    "        pad = ZeroPad2d((0, 0, 0, EMBEDDING_ROWS - cur_no_rows))\n",
    "        loc_embeddings = pad(loc_embeddings)\n",
    "\n",
    "        cur_recording_cycles_embeddings[i] = torch.flatten(loc_embeddings)\n",
    "\n",
    "    cur_recording_cycles_embeddings = torch.flatten(cur_recording_cycles_embeddings)\n",
    "    recording_cycles_embeddings = cur_recording_cycles_embeddings if recording_cycles_embeddings is None else torch.vstack((recording_cycles_embeddings, cur_recording_cycles_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADAM_EPSILON', 'AUDIO_EMBEDDING_FEATURE_NAME', 'EMBEDDING_SIZE', 'EXAMPLE_HOP_SECONDS', 'EXAMPLE_WINDOW_SECONDS', 'INIT_STDDEV', 'INPUT_OP_NAME', 'INPUT_TENSOR_NAME', 'LEARNING_RATE', 'LOG_OFFSET', 'MEL_MAX_HZ', 'MEL_MIN_HZ', 'NUM_BANDS', 'NUM_FRAMES', 'NUM_MEL_BINS', 'OUTPUT_OP_NAME', 'OUTPUT_TENSOR_NAME', 'PCA_EIGEN_VECTORS_NAME', 'PCA_MEANS_NAME', 'PCA_PARAMS', 'Postprocessor', 'QUANTIZE_MAX_VAL', 'QUANTIZE_MIN_VAL', 'SAMPLE_RATE', 'STFT_HOP_LENGTH_SECONDS', 'STFT_WINDOW_LENGTH_SECONDS', 'VGG', 'VGGISH_WEIGHTS', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'hub', 'make_layers', 'mel_features', 'name', 'nn', 'np', 'resampy', 'sf', 'torch', 'torchvggish', 'vggish', 'vggish_input', 'vggish_params', 'waveform_to_examples', 'wavfile_to_examples']\n"
     ]
    }
   ],
   "source": [
    "import torchvggish\n",
    "\n",
    "print(dir(torchvggish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_file = \"C:/Users/lumin/Desktop/Work/20212/Data/circor-heart-sound/final/test/50149_MV.wav\"\n",
    "example_file = \"C:/Users/lumin/Desktop/Work/20212/Data/circor-heart-sound/final/test/13918_MV.wav\"\n",
    "example = vggish_input.wavfile_to_examples(example_file)\n",
    "embeddings = embedding_model.forward(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 128])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68e8aaa6874bd48bb187e47dd02de5530f22ef2f500911b0a3c153188765e172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
